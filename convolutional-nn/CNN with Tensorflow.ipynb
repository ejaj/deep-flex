{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59e9683e-48f7-4c88-8f24-32dfcd71ec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 14:04:43.249589: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-07 14:04:43.389100: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-07 14:04:43.389129: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-07 14:04:43.389929: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-07 14:04:43.470984: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-07 14:04:43.472358: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-07 14:04:44.202076: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.python.framework import ops\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6594b2d5-9e27-4eea-835f-cf85b10be3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "tf = tf.compat.v1\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9207c9b2-ebf5-4385-8142-33b90c083b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 14:04:46.680602: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-07 14:04:46.777715: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2851a8a9-cd90-4178-9153-c6d121c4ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "587e2071-0e1e-413a-841d-5862d3afb0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We then normalize the train and test set features \n",
    "# Z- scoring  or Gaussian Normalization\n",
    "X_train = X_train - np.mean(X_train) / X_train.std()\n",
    "X_test = X_test - np.mean(X_test) / X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f179c99-940a-4b73-acc4-b4f9d5334fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels into one-hot encoded vectors\n",
    "train_labels = y_train\n",
    "test_labels = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d9dfc6d-c7ee-46c7-821d-531187ba1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c77a609-17af-4cf0-8811-d8cc33c0824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters\n",
    "batch_size = 784\n",
    "samples =500\n",
    "learning_rate = 0.03\n",
    "img_width = X_train[0].shape[0]\n",
    "img_height = X_train[0].shape[1]\n",
    "target_size = max(train_labels) + 1\n",
    "num_channels = 1 # greyscale = 1 channel\n",
    "epoch = 3\n",
    "no_channels = 1\n",
    "conv1_features = 30\n",
    "filt1_features = 5\n",
    "conv2_features = 15\n",
    "filt2_features = 3\n",
    "max_pool_size1 = 2 # NxN window for 1st max pool layer\n",
    "max_pool_size2 = 2 # NxN window for 2nd max pool layer\n",
    "fully_connected_size1 = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d100da1-33e5-428f-ae14-7be764248b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0681c4c7-7a3c-4038-acbe-fde548d9d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare model placeholders\n",
    "x_input_shape = (batch_size, img_width, img_height, num_channels)\n",
    "x_input = tf.placeholder(tf.float32, shape=x_input_shape)\n",
    "y_target = tf.placeholder(tf.int32, shape=(batch_size))\n",
    "eval_input_shape = (samples, img_width, img_height, num_channels)\n",
    "eval_input = tf.placeholder(tf.float32, shape=eval_input_shape)\n",
    "eval_target = tf.placeholder(tf.int32, shape=(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d635b21-aa51-49f5-9db8-339391c640c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare model variables\n",
    "W1 = tf.Variable(tf.random_normal([filt1_features, filt1_features, no_channels, conv1_features]))\n",
    "b1 = tf.Variable(tf.ones([conv1_features]))\n",
    "W2 = tf.Variable(tf.random_normal([filt2_features, filt2_features, conv1_features, conv2_features]))\n",
    "b2 = tf.Variable(tf.ones([conv2_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff83d629-4821-4efc-879b-9f4e21b5ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare model variables for fully connected layers\n",
    "resulting_width = img_width // (max_pool_size1 * max_pool_size2)\n",
    "resulting_height = img_height // (max_pool_size1 * max_pool_size2)\n",
    "full1_input_size = resulting_width * resulting_height * conv2_features\n",
    "W3 = tf.Variable(tf.truncated_normal([full1_input_size, fully_connected_size1],\n",
    "                          stddev=0.1, dtype=tf.float32))\n",
    "b3 = tf.Variable(tf.truncated_normal([fully_connected_size1], stddev=0.1, dtype=tf.float32))\n",
    "W_out = tf.Variable(tf.truncated_normal([fully_connected_size1, target_size],\n",
    "                                               stddev=0.1, dtype=tf.float32))\n",
    "b_out = tf.Variable(tf.truncated_normal([target_size], stddev=0.1, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4e315d8-b6f3-401f-8891-22fcad5ffa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions for the convolution and maxpool layers:\n",
    "def conv_layer(x, W, b):\n",
    "    conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    conv_with_b = tf.nn.bias_add(conv, b)\n",
    "    conv_out = tf.nn.elu(conv_with_b)\n",
    "    return conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc3d09c1-6dd7-4441-8d40-6db055b656ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool_layer(conv, k=2):\n",
    "    return tf.nn.max_pool(conv, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5a295b-7d42-48a1-afba-3ff76f6ec885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57c0aa06-79eb-4a97-8ef0-bc69a6f8afa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model Operations\n",
    "def my_conv_net(input_data):\n",
    "    conv_out1 = conv_layer(input_data, W1, b1)\n",
    "    maxpool_out1 = maxpool_layer(conv_out1)\n",
    "    # Second Conv-ReLU-MaxPool Layer\n",
    "    conv_out2 = conv_layer(maxpool_out1, W2, b2)\n",
    "    maxpool_out2 = maxpool_layer(conv_out2)\n",
    "\n",
    "    # Transform Output into a 1xN layer for next fully connected layer\n",
    "    final_conv_shape = maxpool_out2.get_shape().as_list()\n",
    "    final_shape = final_conv_shape[1] * final_conv_shape[2] * final_conv_shape[3]\n",
    "    flat_output = tf.reshape(maxpool_out2, [final_conv_shape[0], final_shape])\n",
    "\n",
    "    # First Fully Connected Layer\n",
    "    fully_connected1 = tf.nn.relu(tf.add(tf.matmul(flat_output, W3), b3))\n",
    "    # Second Fully Connected Layer\n",
    "    final_model_output = tf.add(tf.matmul(fully_connected1, W_out), b_out)\n",
    "\n",
    "    return final_model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03b1a6b2-7553-4720-ae2c-34aed068d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = my_conv_net(x_input)\n",
    "test_model_output = my_conv_net(eval_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ae8ef68-af5b-4da7-a82e-327cf76f56fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Loss Function (softmax cross entropy)\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model_output, labels=y_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fbbbe92-1eae-4bad-8fec-f9ac99ee96c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prediction function\n",
    "prediction = tf.nn.softmax(model_output)\n",
    "test_prediction = tf.nn.softmax(test_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f8eac23-4837-47ee-b49c-3b428833c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create accuracy function\n",
    "def get_accuracy(logits, targets):\n",
    "    batch_predictions = np.argmax(logits, axis=1)\n",
    "    num_correct = np.sum(np.equal(batch_predictions, targets))\n",
    "    return(100. * num_correct/batch_predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67326666-04e6-409b-a24c-9a2328ec2613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 14:09:04.044292: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "# Create an optimizer\n",
    "my_optimizer = tf.train.AdamOptimizer(learning_rate, 0.9)\n",
    "train_step = my_optimizer.minimize(loss)\n",
    "\n",
    "# Initialize Variables\n",
    "varInit = tf.global_variables_initializer()\n",
    "sess.run(varInit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "525356ab-23b5-4917-9af7-fd1a92ee6536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 14:09:15.388154: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 73758720 exceeds 10% of free system memory.\n",
      "2023-12-07 14:09:15.441229: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 27941760 exceeds 10% of free system memory.\n",
      "2023-12-07 14:09:15.441637: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 27941760 exceeds 10% of free system memory.\n",
      "2023-12-07 14:09:15.485748: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 36879360 exceeds 10% of free system memory.\n",
      "2023-12-07 14:09:15.485809: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 73758720 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 1. Train Loss: 136220.16. Train Acc : 9.95 . temp_test_acc : 9.60\n",
      "Epoch # 2. Train Loss: 79646.30. Train Acc : 15.18 . temp_test_acc : 15.80\n",
      "Epoch # 3. Train Loss: 74905.19. Train Acc : 10.33 . temp_test_acc : 10.00\n"
     ]
    }
   ],
   "source": [
    "# Start training loop\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    random_index = np.random.choice(len(X_train), size=batch_size)\n",
    "    random_x = X_train[random_index]\n",
    "    random_x = np.expand_dims(random_x, 3)\n",
    "    random_y = train_labels[random_index]   \n",
    "     \n",
    "    train_dict = {x_input: random_x, y_target: random_y}\n",
    "    \n",
    "    sess.run(train_step, feed_dict=train_dict)\n",
    "    temp_train_loss, temp_train_preds = sess.run([loss, prediction], feed_dict=train_dict)\n",
    "    temp_train_acc = get_accuracy(temp_train_preds, random_y)\n",
    "    \n",
    "    \n",
    "    eval_index = np.random.choice(len(X_test), size=500)\n",
    "    eval_x = X_test[eval_index]\n",
    "    eval_x = np.expand_dims(eval_x, 3)\n",
    "    eval_y = test_labels[eval_index]\n",
    "    test_dict = {eval_input: eval_x, eval_target: eval_y}\n",
    "    test_preds = sess.run(test_prediction, feed_dict=test_dict)\n",
    "    temp_test_acc = get_accuracy(test_preds, eval_y)\n",
    "    # Record and print results\n",
    "    train_loss.append(temp_train_loss)\n",
    "    train_acc.append(temp_train_acc)\n",
    "    test_acc.append(temp_test_acc)\n",
    "    acc_and_loss = [(i+1), temp_train_loss, temp_train_acc, temp_test_acc]\n",
    "    acc_and_loss = [np.round(x,2) for x in acc_and_loss]\n",
    "    print('Epoch # {}. Train Loss: {:.2f}. Train Acc : {:.2f} . temp_test_acc : {:.2f}'.format(i+1,temp_train_loss,temp_train_acc,temp_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d135ce73-fb36-4840-bc07-8e20a332f439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
